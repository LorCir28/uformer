{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_wpJixyu0uG"
      },
      "source": [
        "# Globals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtF7IK-nuqlb",
        "outputId": "59eaab34-ac32-4a6e-f526-5218ba4309c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEN7u0ovvOaU"
      },
      "outputs": [],
      "source": [
        "global_var = {\n",
        "    # Resolutions\n",
        "    'RGB_img_res': (3, 634, 488),\n",
        "    'batch_size': 64,\n",
        "    'n_workers': 2,\n",
        "}\n",
        "\n",
        "augmentation_parameters = {\n",
        "    # TODO\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hQKBwXMv3yI"
      },
      "outputs": [],
      "source": [
        "dataset_root = '/content/drive/MyDrive/NN_project/SSID_dataset/'\n",
        "save_model_root = '/content/drive/MyDrive/NN_project/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KVlRJ0lu7eU"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ2A1RHB2KW_",
        "outputId": "1ca34925-4e7b-4549-a513-59a05bd23b19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: torchsummaryX in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchsummaryX) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchsummaryX) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from torchsummaryX) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsummaryX) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsummaryX) (2022.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchsummaryX) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchsummaryX) (16.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->torchsummaryX) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchsummaryX) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchsummaryX) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install einops torchsummaryX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-ZMoEfcu9gM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as TT\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchsummaryX import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXRFscaCxaY7"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oShoEPlgyVxF"
      },
      "source": [
        "## Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMmArppAyYRS"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhjFnJ-yyaCJ"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LroEZr8QycjJ"
      },
      "outputs": [],
      "source": [
        "class SSID_Dataset(Dataset):\n",
        "    def __init__(self, data_root):\n",
        "        self.dataset_path = data_root\n",
        "        self.dir_list = data_root + \"Scene_Instances.txt\"\n",
        "        self.data_dir = data_root + \"Data/\"\n",
        "        self.data_directiories = []\n",
        "        self.img_paths = []\n",
        "        self.target_paths = []\n",
        "        self.post_processing = TT.Compose([\n",
        "            TT.ToTensor(),\n",
        "            TT.Resize((global_var['RGB_img_res'][2], global_var['RGB_img_res'][1]),antialias=None),\n",
        "        ])\n",
        "\n",
        "        data_dir_file = open(dataset_root+\"Scene_Instances.txt\", 'r')\n",
        "        self.data_directories = [elem.strip() for elem in data_dir_file.readlines()]\n",
        "        data_dir_file.close()\n",
        "\n",
        "        for elem in self.data_directories:\n",
        "          data_path = self.data_dir + elem\n",
        "          content = sorted(os.listdir(data_path))\n",
        "          self.target_paths.append(content[0])\n",
        "          self.img_paths.append(content[1])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.data_dir + self.data_directories[index] + \"/\" + self.img_paths[index]\n",
        "        img = self.post_processing(Image.open(img_path))\n",
        "\n",
        "        target_path = self.data_dir + self.data_directories[index] + \"/\" + self.target_paths[index]\n",
        "        target = self.post_processing(Image.open(target_path))\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyizoOj4yehn"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxVEwFxtyf92",
        "outputId": "0baa03d9-f043-47a4-d475-123de17a4d48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data percentage:  0.7\n",
            "Test data percentage:  0.3\n"
          ]
        }
      ],
      "source": [
        "dataset = SSID_Dataset(dataset_root)\n",
        "train_dataset, test_dataset = random_split(dataset, [112, 48])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size = global_var['batch_size'],\n",
        "                                           num_workers = global_var['n_workers'],\n",
        "                                           shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size = global_var['batch_size'],\n",
        "                                          num_workers = global_var['n_workers'],\n",
        "                                          shuffle = True)\n",
        "\n",
        "print(\"Train data percentage: \", len(train_dataset)/(len(train_dataset)+len(test_dataset)))\n",
        "print(\"Test data percentage: \", len(test_dataset)/(len(train_dataset)+len(test_dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr4UgpsTQNXr"
      },
      "source": [
        "# Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGzJ-r8QQO1V"
      },
      "outputs": [],
      "source": [
        "class loss_function(nn.Module):\n",
        "  def __init__(self,truth, pred, epsilon=1e-3):\n",
        "    super(loss_function,self).__init__()\n",
        "    self.epsilon = epsilon\n",
        "\n",
        "  def forward(self,pred,truth):\n",
        "    return torch.mean(torch.sqrt((pred-truth)**2 + self.epsilon**2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rzLgWkBY50K"
      },
      "source": [
        "## Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Btr_ivEiY73R"
      },
      "outputs": [],
      "source": [
        "class W_MSA(nn.module):\n",
        "  def __init__(self, C, heads, B):\n",
        "    super(W_MSA, self).__init__()\n",
        "    self.C = C\n",
        "    self.B = B\n",
        "    self.heads = heads\n",
        "    self.head_dim = C // heads\n",
        "\n",
        "    self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "    self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "    self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "    self.fc_out = nn.Linear(heads*self.head_dim, C)\n",
        "\n",
        "  def forward(self, values, keys, queries):\n",
        "    attention = torch.softmax((queries*torch.transpose(keys) / self.head_dim) + self.B)\n",
        "    out = attention * values\n",
        "\n",
        "    return self.fc_out(out)\n",
        "\n",
        "\n",
        "class LeFF(nn.module):\n",
        "  def __init__(self, dim=32, hidden_dim=128):\n",
        "    super(LeFF, self).__init__()\n",
        "    self.dim = dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    self.layer1 = nn.Sequential(nn.Linear(dim, hidden_dim), nn.GELU)\n",
        "    self.layer2 = nn.Sequential(nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=1, padding=1), nn.GELU)\n",
        "    self.layer3 = nn.Sequential(nn.Linear(hidden_dim, dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, dim, C, B, heads, dropout):\n",
        "    self.norm1 = nn.LayerNorm(dim)\n",
        "    self.w_msa = W_MSA(C, heads, B)\n",
        "    self.norm2 = nn.LayerNorm(dim)\n",
        "    self.leff = LeFF()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, values, keys, queries):\n",
        "    w_msa = self.w_msa(values, keys, queries)\n",
        "    x = self.dropout(self.norm1(w_msa)) # l'input del layer norm1 è sicuramente sbagliato\n",
        "    x = self.dropout(self.norm2(w_msa))\n",
        "    x = self.leff(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
