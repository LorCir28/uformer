{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_wpJixyu0uG"
      },
      "source": [
        "# Globals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtF7IK-nuqlb",
        "outputId": "59eaab34-ac32-4a6e-f526-5218ba4309c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEN7u0ovvOaU"
      },
      "outputs": [],
      "source": [
        "global_var = {\n",
        "    # Resolutions\n",
        "    'RGB_img_res': (3, 634, 488),\n",
        "    'batch_size': 64,\n",
        "    'n_workers': 2,\n",
        "}\n",
        "\n",
        "augmentation_parameters = {\n",
        "    # TODO\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hQKBwXMv3yI"
      },
      "outputs": [],
      "source": [
        "dataset_root = '/content/drive/MyDrive/NN_project/SSID_dataset/'\n",
        "save_model_root = '/content/drive/MyDrive/NN_project/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KVlRJ0lu7eU"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ2A1RHB2KW_",
        "outputId": "1ca34925-4e7b-4549-a513-59a05bd23b19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: torchsummaryX in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchsummaryX) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchsummaryX) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from torchsummaryX) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsummaryX) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsummaryX) (2022.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchsummaryX) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchsummaryX) (16.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->torchsummaryX) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchsummaryX) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchsummaryX) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "#!pip install einops torchsummaryX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-ZMoEfcu9gM"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as TT\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXRFscaCxaY7"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oShoEPlgyVxF"
      },
      "source": [
        "## Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMmArppAyYRS"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhjFnJ-yyaCJ"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LroEZr8QycjJ"
      },
      "outputs": [],
      "source": [
        "class SSID_Dataset(Dataset):\n",
        "    def __init__(self, data_root):\n",
        "        self.dataset_path = data_root\n",
        "        self.dir_list = data_root + \"Scene_Instances.txt\"\n",
        "        self.data_dir = data_root + \"Data/\"\n",
        "        self.data_directiories = []\n",
        "        self.img_paths = []\n",
        "        self.target_paths = []\n",
        "        self.post_processing = TT.Compose([\n",
        "            TT.ToTensor(),\n",
        "            TT.Resize((global_var['RGB_img_res'][2], global_var['RGB_img_res'][1]),antialias=None),\n",
        "        ])\n",
        "\n",
        "        data_dir_file = open(dataset_root+\"Scene_Instances.txt\", 'r')\n",
        "        self.data_directories = [elem.strip() for elem in data_dir_file.readlines()]\n",
        "        data_dir_file.close()\n",
        "\n",
        "        for elem in self.data_directories:\n",
        "          data_path = self.data_dir + elem\n",
        "          content = sorted(os.listdir(data_path))\n",
        "          self.target_paths.append(content[0])\n",
        "          self.img_paths.append(content[1])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.data_dir + self.data_directories[index] + \"/\" + self.img_paths[index]\n",
        "        img = self.post_processing(Image.open(img_path))\n",
        "\n",
        "        target_path = self.data_dir + self.data_directories[index] + \"/\" + self.target_paths[index]\n",
        "        target = self.post_processing(Image.open(target_path))\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyizoOj4yehn"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxVEwFxtyf92",
        "outputId": "0baa03d9-f043-47a4-d475-123de17a4d48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data percentage:  0.7\n",
            "Test data percentage:  0.3\n"
          ]
        }
      ],
      "source": [
        "dataset = SSID_Dataset(dataset_root)\n",
        "train_dataset, test_dataset = random_split(dataset, [112, 48])\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size = global_var['batch_size'],\n",
        "                          num_workers = global_var['n_workers'],\n",
        "                          shuffle = True)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                         batch_size = global_var['batch_size'],\n",
        "                         num_workers = global_var['n_workers'],\n",
        "                         shuffle = True)\n",
        "\n",
        "print(\"Train data percentage: \", len(train_dataset)/(len(train_dataset)+len(test_dataset)))\n",
        "print(\"Test data percentage: \", len(test_dataset)/(len(train_dataset)+len(test_dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr4UgpsTQNXr"
      },
      "source": [
        "# Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGzJ-r8QQO1V"
      },
      "outputs": [],
      "source": [
        "class loss_function(nn.Module):\n",
        "  def __init__(self,truth, pred, epsilon=1e-3):\n",
        "    super(loss_function,self).__init__()\n",
        "    self.epsilon = epsilon\n",
        "\n",
        "  def forward(self,pred,truth):\n",
        "    return torch.mean(torch.sqrt((pred-truth)**2 + self.epsilon**2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs5YU6PuOhaw"
      },
      "source": [
        "# Evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V90asHFCOhaw"
      },
      "outputs": [],
      "source": [
        "# ATTENTION: PYTORCH HAS PIXEL RANGE BETWEEN 0.0 AND 1.0, NOT BETWEEN 0 AND 255\n",
        "# It works, compared with torchmetrics.image import PeakSignalNoiseRatio\n",
        "def psnr(original_img, compressed_img, max_pix_val=1.0):\n",
        "  mse = torch.mean((original_img-compressed_img)**2)\n",
        "  return 20 * torch.log10(max_pix_val/torch.sqrt(mse))\n",
        "\n",
        "import cv2\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor([math.exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
        "    return gauss/gauss.sum()\n",
        "\n",
        "def create_window(window_size, channel=1):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n",
        "    return window\n",
        "\n",
        "# ATTENTION: PYTORCH HAS PIXEL RANGE BETWEEN 0.0 AND 1.0, NOT BETWEEN 0 AND 255\n",
        "# ATTENTION: 4D tensors needed\n",
        "# It works, compared with StructuralSimilarityIndexMeasure from torchmetrics.image\n",
        "def ssim(original_img, restored_img, max_pix_val=1.0, window_size=11, window=None, size_average=True, full=False):\n",
        "    (_, channel, height, width) = original_img.size()\n",
        "    real_size = min(window_size, height, width)    \n",
        "    window = create_window(real_size, channel=channel).to(original_img.device)\n",
        "\n",
        "    mu1 = F.conv2d(original_img, window, padding=0, groups=channel)\n",
        "    mu2 = F.conv2d(restored_img, window, padding=0, groups=channel)\n",
        "\n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "\n",
        "    sigma1_sq = F.conv2d(original_img ** 2, window, padding=0, groups=channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(restored_img ** 2, window, padding=0, groups=channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(original_img * restored_img, window, padding=0, groups=channel) - mu1_mu2\n",
        "\n",
        "    C1 = (0.01 * max_pix_val) ** 2\n",
        "    C2 = (0.03 * max_pix_val) ** 2\n",
        "\n",
        "    v1 = 2.0 * sigma12 + C2\n",
        "    v2 = sigma1_sq + sigma2_sq + C2\n",
        "    cs = torch.mean(v1 / v2)\n",
        "\n",
        "    return (((2 * mu1_mu2 + C1) * v1) / ((mu1_sq + mu2_sq + C1) * v2)).mean()\n",
        "\n",
        "\n",
        "def compute_evaluation(test_dataloader, model, device='cpu'):\n",
        "  model.eval()\n",
        "  psnr_values = []\n",
        "  ssim_values = []\n",
        "\n",
        "  for i, (inputs, targets) in enumerate(test_dataloader):\n",
        "      inputs, targets = inputs.to(device=device), targets.to(device=device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          predictions = model(inputs)\n",
        "\n",
        "      psnr_values.append(psnr(targets,predictions))\n",
        "      ssim_values.append(ssim(targets,predictions, val_range=1000.0))\n",
        "\n",
        "  return np.mean(np.array(psnr_values)),np.mean(np.array(ssim_values)),"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rzLgWkBY50K"
      },
      "source": [
        "# Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Btr_ivEiY73R"
      },
      "outputs": [],
      "source": [
        "# attention components\n",
        "\n",
        "class W_MSA(nn.module):\n",
        "  def __init__(self, C, heads, B):\n",
        "    super(W_MSA, self).__init__()\n",
        "    self.C = C\n",
        "    self.B = B\n",
        "    self.heads = heads\n",
        "    self.head_dim = C // heads\n",
        "\n",
        "    self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "    self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "    self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "    self.fc_out = nn.Linear(heads*self.head_dim, C)\n",
        "\n",
        "  def forward(self, values, keys, queries):\n",
        "    attention = torch.softmax((queries*torch.transpose(keys) / self.head_dim) + self.B)\n",
        "    out = attention * values\n",
        "\n",
        "    return self.fc_out(out)\n",
        "\n",
        "\n",
        "class LeFF(nn.module):\n",
        "  def __init__(self, dim=32, hidden_dim=128):\n",
        "    super(LeFF, self).__init__()\n",
        "    self.dim = dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    self.layer1 = nn.Sequential(nn.Linear(dim, hidden_dim), nn.GELU)\n",
        "    self.layer2 = nn.Sequential(nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=1, padding=1), nn.GELU)\n",
        "    self.layer3 = nn.Sequential(nn.Linear(hidden_dim, dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# NN BLOCKS\n",
        "\n",
        "# LeWin Transformer Block\n",
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, dim, C, B, heads, dropout):\n",
        "    self.norm1 = nn.LayerNorm(dim)\n",
        "    self.w_msa = W_MSA(C, heads, B)\n",
        "    self.norm2 = nn.LayerNorm(dim)\n",
        "    self.leff = LeFF()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, values, keys, queries):\n",
        "    w_msa = self.w_msa(values, keys, queries)\n",
        "    x = self.dropout(self.norm1(w_msa)) # l'input del layer norm1 è sicuramente sbagliato\n",
        "    x = self.dropout(self.norm2(w_msa))\n",
        "    x = self.leff(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "# Down-sampling Block (reduces the size of the feature map)\n",
        "# reshape the flattened features into 2D spatial feature maps, and then down-sample the maps, double the channels using 4 × 4 convolution with stride 2\n",
        "class DownsampleBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel):\n",
        "        super(Downsample, self).__init__()\n",
        "        self.in_channel = in_channel\n",
        "        self.out_channel = out_channel\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channel, out_channel, kernel_size=4, stride=2, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x): # remember that x is a tensor!!\n",
        "        B, L, C = x.shape\n",
        "        H = int(math.sqrt(L))\n",
        "        W = int(math.sqrt(L))\n",
        "        x = x.transpose(1, 2).contiguous().view(B, C, H, W) # this transposes the 1st and 2nd dimension of x, then the size of x is reshaped with view (the new size is (B, C, H, W))\n",
        "                                                            # (.contiguous() is required to make view workable, since view works only on contiguous data)\n",
        "\n",
        "        out = self.conv(x).flatten(2).transpose(1, 2).contiguous() # this pass the input x to the downsample layer, then the 2nd dimension of the output is flattened with the 3rd\n",
        "                                                                   # and finally its 1st and 2nd dimensions are transposed\n",
        "\n",
        "                                                                   # (B, C, H*W) is the size of the out after flatten(2)\n",
        "                                                                   # (B H*W C) is the final size of the out after transpose(1, 2)\n",
        "        return out\n",
        "\n",
        "\n",
        "# Up-sampling Block (reduces half of the channels and doubles the size of the feature map)\n",
        "# 2 × 2 transposed convolution with stride 2\n",
        "class UpsampleBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel):\n",
        "      self.in_channel = in_channel\n",
        "      self.out_channel = out_channel\n",
        "      super(Upsample, self).__init__()\n",
        "      self.deconv = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channel, out_channel, kernel_size=2, stride=2),\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      B, L, C = x.shape\n",
        "      H = int(math.sqrt(L))\n",
        "      W = int(math.sqrt(L))\n",
        "      x = x.transpose(1, 2).contiguous().view(B, C, H, W)\n",
        "      out = self.deconv(x).flatten(2).transpose(1, 2).contiguous() # B H*W C\n",
        "\n",
        "      return out\n",
        "\n",
        "\n",
        "# Input Projection Block (extracts the low-level features)\n",
        "# 3 x 3 convolutional layer with LeakyReLu\n",
        "class InputProjBlock(nn.Module):\n",
        "    def __init__(self, in_channel=3, out_channel=64):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=1, padding=kernel_size//2),\n",
        "            nn.LeakyReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        x = self.proj(x).flatten(2).transpose(1, 2).contiguous()  # B H*W C\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "# Output Projection Block (returns the residual R)\n",
        "# 3 x 3 convolutional layer\n",
        "class OutputProjBlock(nn.Module):\n",
        "    def __init__(self, in_channel=64, out_channel=3):\n",
        "        super().__init__()\n",
        "        self.in_channel = in_channel\n",
        "        self.out_channel = out_channel\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=1, padding=kernel_size//2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, L, C = x.shape\n",
        "        H = int(math.sqrt(L))\n",
        "        W = int(math.sqrt(L))\n",
        "        x = x.transpose(1, 2).view(B, C, H, W)\n",
        "        x = self.proj(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "# AFTER THE OUTPUT PROJECTION, WE HAVE TO SUM UP THE RESIDUAL R AND THE ORIGINAL INPUT (DEGRADED IMAGE I) TO OBTAIN THE RESTORED IMAGE I'\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
