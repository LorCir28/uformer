{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_wpJixyu0uG"
      },
      "source": [
        "# Globals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtF7IK-nuqlb",
        "outputId": "a8b701a7-6088-44ae-d9f4-29c89fbe1da1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {
        "id": "kEN7u0ovvOaU"
      },
      "outputs": [],
      "source": [
        "global_var = {\n",
        "    # Resolutions\n",
        "    'RGB_img_res': (3, 16, 64), # Tensor.shape = [Batch, Channel, Height, Width]\n",
        "    'patch_size' : 32,\n",
        "\n",
        "    # Parameters\n",
        "    'batch_size': 8,\n",
        "    'eval_batch_size': 1,\n",
        "    'n_workers': 2,\n",
        "    'lr': 2e-3,\n",
        "    'epochs': 100,\n",
        "    'n_workers': 2,\n",
        "\n",
        "    # Operations\n",
        "    'do_print_model': True,\n",
        "    'use_full_dataset': True,\n",
        "    'verbose': True,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {
        "id": "0hQKBwXMv3yI"
      },
      "outputs": [],
      "source": [
        "dataset_root = '/content/drive/MyDrive/NN_project/SSID_dataset/'\n",
        "full_dataset_root = '/content/drive/MyDrive/NN_project/Full_SSID_dataset/'\n",
        "save_model_root = '/content/drive/MyDrive/NN_project/'\n",
        "model_name = \"Uformer\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KVlRJ0lu7eU"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {
        "id": "tJ2A1RHB2KW_"
      },
      "outputs": [],
      "source": [
        "!pip install einops torchsummaryX --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {
        "id": "x-ZMoEfcu9gM"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as TT\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchsummaryX import summary\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smh0pVrvtHTZ"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {
        "id": "ZlZooBR0tO_D"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(y_pred, y_true, thr=0.05):\n",
        "  valid_mask = y_true > 0.0\n",
        "  valid_pred = y_pred[valid_mask]\n",
        "  valid_true = y_true[valid_mask]\n",
        "  correct = torch.max((valid_true / valid_pred), (valid_pred / valid_true)) < (1 + thr)\n",
        "  return 100 * torch.mean(correct.float())\n",
        "\n",
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "  for param_group in optimizer.param_groups:\n",
        "      return param_group['lr']\n",
        "\n",
        "def hardware_check():\n",
        "  device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "  print(\"Actual device: \", device)\n",
        "  return device\n",
        "\n",
        "def load_pretrained_model(model, device):\n",
        "  print(\"Loading checkpoint...\\n\")\n",
        "  model_dict = torch.load(save_model_root+\"/Uformer_best_acc\", map_location=torch.device(device))\n",
        "  model.load_state_dict(model_dict)\n",
        "  print(\"Checkpoint loaded!\\n\")\n",
        "  return model\n",
        "\n",
        "def plot_graph(f, g, f_label, g_label, title, path):\n",
        "  epochs = range(0, len(f))\n",
        "  plt.plot(epochs, f, 'b', label=f_label)\n",
        "  plt.plot(epochs, g, 'orange', label=g_label)\n",
        "  plt.title(title)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "  plt.grid('on', color='#cfcfcf')\n",
        "  plt.tight_layout()\n",
        "  plt.savefig(path + title + '.pdf')\n",
        "  plt.close()\n",
        "\n",
        "def plot_history(history):\n",
        "  plot_graph(history['train_loss'], history['val_loss'], 'Train Loss', 'Val. Loss', 'TrainVal_loss', save_model_root)\n",
        "  plot_graph(history['train_acc'], history['val_acc'], 'Train Acc.', 'Val. Acc.', 'TrainVal_acc', save_model_root)\n",
        "\n",
        "def plot_loss(history,title):\n",
        "  l_train_list = history['train_loss']\n",
        "  l_test_list = history['val_loss']\n",
        "  epochs = range(0, len(global_var['epochs']))\n",
        "\n",
        "  plt.plot(epochs, l_train_list, 'r', label='Train loss')\n",
        "  plt.plot(epochs, l_test_list, 'g', label='Test loss')\n",
        "  plt.title(title)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.grid('on', color='#cfcfcf')\n",
        "  plt.legend()\n",
        "  plt.tight_layout()\n",
        "  plt.savefig(save_model_root + \"/\" + title + '.pdf')\n",
        "  plt.close()\n",
        "\n",
        "def print_model(model, device, input_shape):\n",
        "  info = summary(model, torch.ones((global_var['batch_size'], input_shape[0], input_shape[1], input_shape[2])).to(device))\n",
        "  info.to_csv(save_model_root + 'model_summary.csv')\n",
        "\n",
        "def save_checkpoint(model, name):\n",
        "  torch.save(model.state_dict(), save_model_root + name)\n",
        "\n",
        "def save_csv_history(model_name):\n",
        "  objects = []\n",
        "  with (open(save_model_root + model_name + '_history.pkl', \"rb\")) as openfile:\n",
        "      while True:\n",
        "          try:\n",
        "              objects.append(pickle.load(openfile))\n",
        "          except EOFError:\n",
        "              break\n",
        "  df = pd.DataFrame(objects)\n",
        "  df.to_csv(save_model_root + model_name + '_history.csv', header=False, index=False, sep=\" \")\n",
        "\n",
        "def save_history(history, filepath):\n",
        "  tmp_file = open(filepath + '.pkl', \"wb\")\n",
        "  pickle.dump(history, tmp_file)\n",
        "  tmp_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXRFscaCxaY7"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhjFnJ-yyaCJ"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {
        "id": "LroEZr8QycjJ"
      },
      "outputs": [],
      "source": [
        "from tables.index import idx2long\n",
        "class SSID_Dataset(Dataset):\n",
        "  def __init__(self, data_root, full=True):\n",
        "    assert os.path.exists(data_root)\n",
        "    super(SSID_Dataset, self).__init__()\n",
        "\n",
        "    self.full_dataset = full\n",
        "    self.instances_list_path = data_root + \"Scene_Instances.txt\"\n",
        "    self.data_directories_path = data_root + \"Data/\"\n",
        "\n",
        "    self.img_paths = []\n",
        "    self.target_paths = []\n",
        "    self.dataset_size = 0\n",
        "\n",
        "    instances_list_file = open(self.instances_list_path, 'r')\n",
        "    data_directories = [self.data_directories_path + elem.strip()+\"/\" for elem in instances_list_file.readlines()]\n",
        "    instances_list_file.close()\n",
        "\n",
        "    for elem in data_directories:\n",
        "      content = sorted(os.listdir(elem))\n",
        "\n",
        "      if(self.full_dataset):\n",
        "        self.target_paths.append(elem+content[0])\n",
        "        self.target_paths.append(elem+content[1])\n",
        "        self.img_paths.append(elem+content[2])\n",
        "        self.img_paths.append(elem+content[3])\n",
        "      else:\n",
        "        self.target_paths.append(elem+content[0])\n",
        "        self.img_paths.append(elem+content[1])\n",
        "\n",
        "    self.dataset_size = len(self.img_paths)\n",
        "\n",
        "  def __len__(self):\n",
        "      return self.dataset_size\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      idx = index % self.dataset_size # Avoid going beyond limits\n",
        "\n",
        "      raw_noise_img = np.float32(cv2.cvtColor(cv2.imread(self.img_paths[idx]), cv2.COLOR_BGR2RGB))\n",
        "      noise_img = torch.from_numpy(raw_noise_img).permute(2,0,1)\n",
        "\n",
        "      raw_gt_img = np.float32(cv2.cvtColor(cv2.imread(self.target_paths[idx]), cv2.COLOR_BGR2RGB))\n",
        "      gt_img = torch.from_numpy(raw_gt_img).permute(2,0,1)\n",
        "\n",
        "      ps = global_var['patch_size']\n",
        "      H = gt_img.shape[1]\n",
        "      W = gt_img.shape[2]\n",
        "      # r = np.random.randint(0, H - ps) if not H-ps else 0\n",
        "      # c = np.random.randint(0, W - ps) if not H-ps else 0\n",
        "      if H-ps==0:\n",
        "          r=0\n",
        "          c=0\n",
        "      else:\n",
        "          r = np.random.randint(0, H - ps)\n",
        "          c = np.random.randint(0, W - ps)\n",
        "      gt_img = gt_img[:, r:r + ps, c:c + ps]\n",
        "      noise_img = noise_img[:, r:r + ps, c:c + ps]\n",
        "\n",
        "      return noise_img, gt_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyizoOj4yehn"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxVEwFxtyf92",
        "outputId": "563c6f1f-8adf-4532-a5a7-006a36191429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using full SSID dataset with 320 samples\n",
            "Train size:  256\n",
            "Test size:  64\n",
            "Train data percentage:  0.8\n",
            "Test data percentage:  0.2\n"
          ]
        }
      ],
      "source": [
        "if(global_var['use_full_dataset']):\n",
        "  dataset = SSID_Dataset(full_dataset_root)\n",
        "  print(\"Using full SSID dataset with %d samples\" % dataset.__len__())\n",
        "  train_dataset, test_dataset = random_split(dataset, [256, 64])\n",
        "\n",
        "else:\n",
        "  dataset = SSID_Dataset(dataset_root,False)\n",
        "  print(\"Using partial SSID dataset with %d samples\" % dataset.__len__())\n",
        "  train_dataset, test_dataset = random_split(dataset, [128, 32])\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size = global_var['batch_size'],\n",
        "                          num_workers = global_var['n_workers'],\n",
        "                          shuffle = True)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                         batch_size = global_var['eval_batch_size'],\n",
        "                         num_workers = global_var['n_workers'],\n",
        "                         shuffle = True)\n",
        "\n",
        "print(\"Train size: \", len(train_dataset))\n",
        "print(\"Test size: \", len(test_dataset))\n",
        "print(\"Train data percentage: \", len(train_dataset)/(len(train_dataset)+len(test_dataset)))\n",
        "print(\"Test data percentage: \", len(test_dataset)/(len(train_dataset)+len(test_dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr4UgpsTQNXr"
      },
      "source": [
        "# Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {
        "id": "UGzJ-r8QQO1V"
      },
      "outputs": [],
      "source": [
        "# class Cha_loss(nn.Module):\n",
        "#   def __init__(self, epsilon=1e-3):\n",
        "#     super(Cha_loss,self).__init__()\n",
        "#     self.epsilon = epsilon\n",
        "\n",
        "#   def forward(self,pred,truth):\n",
        "#     return torch.mean(torch.sqrt((pred-truth)**2 + self.epsilon**2))\n",
        "\n",
        "class Cha_loss(nn.Module):\n",
        "    \"\"\"Charbonnier Loss (L1)\"\"\"\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super(Cha_loss, self).__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        b, c, h, w = y.size()\n",
        "        loss = torch.sum(torch.sqrt((x - y).pow(2) + self.eps**2))\n",
        "        return loss/(c*b*h*w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maczFOi8eB52"
      },
      "source": [
        "# Evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 348,
      "metadata": {
        "id": "Wm4POhkmeDsJ"
      },
      "outputs": [],
      "source": [
        "# ATTENTION: PYTORCH HAS PIXEL RANGE BETWEEN 0.0 AND 1.0, NOT BETWEEN 0 AND 255\n",
        "# It works, compared with torchmetrics.image import PeakSignalNoiseRatio\n",
        "def psnr(original_img, compressed_img, max_pix_val=255):\n",
        "  mse = torch.mean((original_img-compressed_img)**2)\n",
        "  return 20 * torch.log10(max_pix_val/torch.sqrt(mse))\n",
        "\n",
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor([math.exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
        "    return gauss/gauss.sum()\n",
        "\n",
        "def create_window(window_size, channel=1):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n",
        "    return window\n",
        "\n",
        "# ATTENTION: PYTORCH HAS PIXEL RANGE BETWEEN 0.0 AND 1.0, NOT BETWEEN 0 AND 255\n",
        "# ATTENTION: 4D tensors needed\n",
        "# It works, compared with StructuralSimilarityIndexMeasure from torchmetrics.image\n",
        "def ssim(original_img, restored_img, max_pix_val=255, window_size=11, window=None, size_average=True, full=False):\n",
        "    (_, channel, height, width) = original_img.size()\n",
        "    real_size = min(window_size, height, width)\n",
        "    window = create_window(real_size, channel=channel).to(original_img.device)\n",
        "\n",
        "    mu1 = F.conv2d(original_img, window, padding=0, groups=channel)\n",
        "    mu2 = F.conv2d(restored_img, window, padding=0, groups=channel)\n",
        "\n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "\n",
        "    sigma1_sq = F.conv2d(original_img ** 2, window, padding=0, groups=channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(restored_img ** 2, window, padding=0, groups=channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(original_img * restored_img, window, padding=0, groups=channel) - mu1_mu2\n",
        "\n",
        "    C1 = (0.01 * max_pix_val) ** 2\n",
        "    C2 = (0.03 * max_pix_val) ** 2\n",
        "\n",
        "    v1 = 2.0 * sigma12 + C2\n",
        "    v2 = sigma1_sq + sigma2_sq + C2\n",
        "\n",
        "    return (((2 * mu1_mu2 + C1) * v1) / ((mu1_sq + mu2_sq + C1) * v2)).mean()\n",
        "\n",
        "\n",
        "def compute_evaluation(test_dataloader, model, device='cpu'):\n",
        "  model.eval()\n",
        "  psnr_values = []\n",
        "  ssim_values = []\n",
        "\n",
        "  for _, (inputs, targets) in enumerate(test_dataloader):\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          predictions = model(inputs)\n",
        "\n",
        "      psnr_values.append(psnr(targets,predictions))\n",
        "      ssim_values.append(ssim(targets,predictions))\n",
        "\n",
        "  return torch.mean(torch.Tensor(psnr_values)).item(),torch.mean(torch.Tensor(ssim_values)).item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rzLgWkBY50K"
      },
      "source": [
        "# Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 340,
      "metadata": {
        "id": "Btr_ivEiY73R"
      },
      "outputs": [],
      "source": [
        "# Attention components\n",
        "# attention module\n",
        "# Attention module with window attention\n",
        "class W_MSA(nn.Module):\n",
        "  def __init__(self, dim=32, num_heads=8, qkv_bias=False):\n",
        "    super(W_MSA, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = dim // num_heads\n",
        "    self.dim = dim\n",
        "\n",
        "    # nn.Linear(in_features, out_features): the input of the layer has to have the last dimension equal to in_features (namely (*, in_features)). The output of the layer has the\n",
        "    # same dimension of the input except for the last one which is equal to out_features (namely (*, out_features))\n",
        "\n",
        "    # self.qkv = nn.Linear(dim, num_heads, self.head_dim, bias=qkv_bias) # this layer returns the queries, keys and values\n",
        "    self.qkv = nn.Linear(dim, self.head_dim*self.num_heads*3, bias=qkv_bias)\n",
        "\n",
        "    # these are default layers for the attention module\n",
        "    self.proj = nn.Linear(dim, dim)\n",
        "    self.proj_drop = nn.Dropout(0.)\n",
        "    self.attn_drop = nn.Dropout(0.)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, N, C = x.shape\n",
        "    # print(\"********* x shape: \",x.shape)\n",
        "    # print(\"********* self qkv shape:\",self.qkv(x).shape)\n",
        "\n",
        "    # feature map split\n",
        "    H = int(math.sqrt(N))\n",
        "    W = int(math.sqrt(N))\n",
        "    M = 2 # choosen arbitrarily\n",
        "    # torch.split(x, M**2)\n",
        "    # attentions_tensor = torch.zeros((H*W)//(M**2))\n",
        "    attentions_tensor = []\n",
        "    splitted = torch.split(x, M**2)\n",
        "    # print(\"************************** total len: \", len(splitted))\n",
        "    for i in range(len(splitted)):\n",
        "      # print(\"************************** i: \", i)\n",
        "      # print(\"************************** item shape: \", splitted[i].shape)\n",
        "      b, n, c = splitted[i].shape\n",
        "      qkv_temp = self.qkv(splitted[i].flatten(2))\n",
        "      mult = qkv_temp.shape[0] * qkv_temp.shape[1] * qkv_temp.shape[2]\n",
        "      mult = mult//3\n",
        "      mult = mult//(self.num_heads*4)\n",
        "\n",
        "      if(B==global_var['batch_size']):\n",
        "        mult = mult//global_var['batch_size']\n",
        "      else:\n",
        "        mult = mult//global_var['eval_batch_size']\n",
        "\n",
        "      qkv = qkv_temp.reshape(B, mult, self.num_heads*4, 3)\n",
        "      q, k, v = qkv.unbind(dim=-1) # this returnes a tuple of tensors whose each element is portion of the original tensor (qkv) (ref: https://pytorch.org/docs/stable/generated/torch.unbind.html)\n",
        "\n",
        "      scale = (C // self.head_dim) ** (0.5)\n",
        "      attn = ((q @ k.transpose(-2, -1)) // scale) + B # from the github: the final B can be also removed\n",
        "      attn = attn.softmax(dim=1)\n",
        "      attn = self.attn_drop(attn)\n",
        "      x = (attn @ v).transpose(1, 2).reshape(b, n, c)\n",
        "\n",
        "      # attentions_tensor.add(x)\n",
        "      attentions_tensor.append(x)\n",
        "\n",
        "    x = attentions_tensor[0]\n",
        "    for i, t in enumerate(attentions_tensor):\n",
        "      if (i == 0):\n",
        "        continue\n",
        "      x = torch.cat([attentions_tensor[i], x], -1)\n",
        "\n",
        "    x = x.reshape([x.shape[0]*(x.shape[2]//self.dim), x.shape[1], x.shape[2]//(x.shape[2]//self.dim)])\n",
        "    # print(\"****************************** final x shape:\", x.shape)\n",
        "    x = self.proj(x)\n",
        "    x = self.proj_drop(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "    # qkv_temp = self.qkv(x)\n",
        "    # mult = qkv_temp.shape[0] * qkv_temp.shape[1] * qkv_temp.shape[2]\n",
        "    # mult = mult//3\n",
        "    # mult = mult//(self.num_heads*4)\n",
        "\n",
        "    # if(B==global_var['batch_size']):\n",
        "    #   mult = mult//global_var['batch_size']\n",
        "    # else:\n",
        "    #   mult = mult//global_var['eval_batch_size']\n",
        "\n",
        "    # qkv = qkv_temp.reshape(B, mult, self.num_heads*4, 3)\n",
        "    # # qkv = self.qkv(x).reshape(B, N, self.num_heads*3, C // self.num_heads).permute(2, 0, 3, 1)\n",
        "    # # print(\"QKV: \",self.qkv(x).shape)\n",
        "    # # print(\"QKV reshaped: \",self.qkv(x).reshape(B, mult, self.num_heads*4, 3).shape)\n",
        "\n",
        "    # # print(\"********* qkv shape:\",qkv.shape)\n",
        "    # q, k, v = qkv.unbind(dim=-1) # this returnes a tuple of tensors whose each element is portion of the original tensor (qkv) (ref: https://pytorch.org/docs/stable/generated/torch.unbind.html)\n",
        "\n",
        "    # # this is the implementation of the attention formula described on the paper\n",
        "    # scale = (C // self.head_dim) ** (0.5)\n",
        "    # attn = ((q @ k.transpose(-2, -1)) // scale) + B # from the github: the final B can be also removed\n",
        "    # attn = attn.softmax(dim=1)\n",
        "    # attn = self.attn_drop(attn)\n",
        "    # # print(\"********** x no reshape:\",(attn @ v).transpose(1, 2).shape)\n",
        "    # x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "\n",
        "    # # these are default for the attention module\n",
        "    # x = self.proj(x)\n",
        "    # x = self.proj_drop(x)\n",
        "\n",
        "    # return x\n",
        "\n",
        "# this is the simple implementation described in the paper\n",
        "class LeFF(nn.Module):\n",
        "  def __init__(self, dim=32, hidden_dim=128):\n",
        "    super(LeFF, self).__init__()\n",
        "    self.dim = dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    self.layer1 = nn.Sequential(nn.Linear(dim, hidden_dim), nn.GELU())\n",
        "    self.layer2 = nn.Sequential(nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=1, padding=1), nn.GELU())\n",
        "    self.layer3 = nn.Sequential(nn.Linear(hidden_dim, dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    # print(\"Before 1st layer x: \", x.shape)\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x.permute(2,1,0))\n",
        "    x = self.layer3(x.permute(2,1,0))\n",
        "\n",
        "    return x\n",
        "\n",
        "  # def forward(self, x):\n",
        "  #   # bs x hw x c\n",
        "  #   bs, hw, c = x.size()\n",
        "  #   hh = int(math.sqrt(hw))\n",
        "\n",
        "  #   x = self.layer1(x)\n",
        "\n",
        "  #   # spatial restore\n",
        "  #   x = rearrange(x, ' b (h w) (c) -> b c h w ', h = hh, w = hh)\n",
        "\n",
        "  #   x = self.layer2(x)\n",
        "\n",
        "  #   # flatten\n",
        "  #   x = rearrange(x, ' b c h w -> b (h w) c', h = hh, w = hh)\n",
        "\n",
        "  #   x = self.layer3(x)\n",
        "\n",
        "  #   return x\n",
        "\n",
        "# NN BLOCKS\n",
        "# LeWin Transformer Block (from the paper, it is made up of a sequence of: NormLayer, W_MSA, NormLayer, LeFF)\n",
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, dim):\n",
        "    super().__init__()\n",
        "    self.norm1 = nn.LayerNorm(dim)\n",
        "    self.w_msa = W_MSA(dim=dim)\n",
        "    self.norm2 = nn.LayerNorm(dim)\n",
        "    self.leff = LeFF(dim=dim)\n",
        "    self.dropout = nn.Dropout(0.)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.dropout(self.norm1(x))\n",
        "    x = self.w_msa(x)\n",
        "    x = self.dropout(self.norm2(x))\n",
        "    x = self.leff(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Down-sampling Block (reduces the size of the feature map)\n",
        "# reshape the flattened features into 2D spatial feature maps, and then down-sample the maps, double the channels using 4 × 4 convolution with stride 2\n",
        "class DownsampleBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel):\n",
        "        super(DownsampleBlock, self).__init__()\n",
        "        self.in_channel = in_channel\n",
        "        self.out_channel = out_channel\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channel, out_channel, kernel_size=4, stride=2, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x): # remember that x is a tensor!!\n",
        "        B, L, C = x.shape\n",
        "        H = int(math.sqrt(L))\n",
        "        W = int(math.sqrt(L))\n",
        "        # print(\"*************** x: \",x.shape)\n",
        "        x = x.transpose(1, 2).contiguous().view(B, C, H, W) # this transposes the 1st and 2nd dimension of x, then the size of x is reshaped with view (the new size is (B, C, H, W))\n",
        "                                                            # (.contiguous() is required to make view workable, since view works only on contiguous data)\n",
        "\n",
        "        out = self.conv(x).flatten(2).transpose(1, 2).contiguous() # this pass the input x to the downsample layer, then the 2nd dimension of the output is flattened with the 3rd\n",
        "                                                                   # and finally its 1st and 2nd dimensions are transposed\n",
        "\n",
        "                                                                   # (B, C, H*W) is the size of the out after flatten(2)\n",
        "                                                                   # (B H*W C) is the final size of the out after transpose(1, 2)\n",
        "        return out\n",
        "\n",
        "\n",
        "# Up-sampling Block (reduces half of the channels and doubles the size of the feature map)\n",
        "# 2 × 2 transposed convolution with stride 2\n",
        "class UpsampleBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, kernel_size, stride, padding):\n",
        "      super(UpsampleBlock, self).__init__()\n",
        "      self.in_channel = in_channel\n",
        "      self.out_channel = out_channel\n",
        "      self.deconv = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride,padding=padding),\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      B, L, C = x.shape\n",
        "      H = int(math.sqrt(L))\n",
        "      W = int(math.sqrt(L))\n",
        "      x = x.transpose(1, 2).contiguous().view(B, C, H, W)\n",
        "      out = self.deconv(x).flatten(2).transpose(1, 2).contiguous() # B H*W C\n",
        "\n",
        "      return out\n",
        "\n",
        "# Input Projection Block (extracts the low-level features)\n",
        "# 3 x 3 convolutional layer with LeakyReLu\n",
        "class InputProjBlock(nn.Module):\n",
        "    def __init__(self, in_channel=3, out_channel=32, kernel_size=3):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=1, padding=kernel_size//2),\n",
        "            nn.LeakyReLU(0.1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        x = self.proj(x).flatten(2).transpose(1, 2).contiguous()  # B H*W C\n",
        "\n",
        "        return x\n",
        "\n",
        "# Output Projection Block (returns the residual)\n",
        "# 3 x 3 convolutional layer\n",
        "class OutputProjBlock(nn.Module):\n",
        "    def __init__(self, in_channel=64, out_channel=3, kernel_size=3):\n",
        "        super().__init__()\n",
        "        self.in_channel = in_channel\n",
        "        self.out_channel = out_channel\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=1, padding=kernel_size//2),\n",
        "            nn.LeakyReLU(0.1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, L, C = x.shape\n",
        "        H = int(math.sqrt(L))\n",
        "        W = int(math.sqrt(L))\n",
        "        x = x.transpose(1, 2).view(B, C, H, W)\n",
        "        x = self.proj(x)\n",
        "\n",
        "        return x # the output of this block si called residual\n",
        "\n",
        "# complete uformer class\n",
        "class Uformer(nn.Module):\n",
        "  def __init__(self, embed_dim=32):\n",
        "    super(Uformer, self).__init__()\n",
        "\n",
        "    # encoder\n",
        "    self.input_proj = InputProjBlock()\n",
        "\n",
        "    self.tranformerblock_0 = TransformerBlock(embed_dim)\n",
        "    self.downsample_0 = DownsampleBlock(embed_dim, embed_dim*2)\n",
        "\n",
        "    self.tranformerblock_1 = TransformerBlock(embed_dim*2)\n",
        "    self.downsample_1 = DownsampleBlock(embed_dim*2, embed_dim*4)\n",
        "\n",
        "    self.tranformerblock_2 = TransformerBlock(embed_dim*4)\n",
        "    self.downsample_2 = DownsampleBlock(embed_dim*4, embed_dim*8)\n",
        "\n",
        "    self.tranformerblock_3 = TransformerBlock(embed_dim*8)\n",
        "    self.downsample_3 = DownsampleBlock(embed_dim*8, embed_dim*16)\n",
        "\n",
        "\n",
        "    # bottleneck\n",
        "    self.tranformerblock_4 = TransformerBlock(embed_dim*16)\n",
        "\n",
        "\n",
        "    # decoder\n",
        "    self.upsample_0 = UpsampleBlock(embed_dim*16, embed_dim*8,kernel_size=2,stride=2,padding=0)\n",
        "    self.tranformerblock_5 = TransformerBlock(embed_dim*16)\n",
        "\n",
        "    self.upsample_1 = UpsampleBlock(embed_dim*16, embed_dim*4,kernel_size=2,stride=2,padding=0)\n",
        "    self.tranformerblock_6 = TransformerBlock(embed_dim*8)\n",
        "\n",
        "    self.upsample_2 = UpsampleBlock(embed_dim*8, embed_dim*2,kernel_size=2,stride=2,padding=0)\n",
        "    self.tranformerblock_7 = TransformerBlock(embed_dim*4)\n",
        "\n",
        "    self.upsample_3 = UpsampleBlock(embed_dim*4, embed_dim,kernel_size=2,stride=2,padding=0)\n",
        "    self.tranformerblock_8 = TransformerBlock(embed_dim*2)\n",
        "\n",
        "    self.output_proj = OutputProjBlock()\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    degraded_image = x # x is the degraded image\n",
        "\n",
        "\n",
        "    # encoder\n",
        "    y = self.input_proj(x)\n",
        "    t0 = self.tranformerblock_0(y)\n",
        "    d0 = self.downsample_0(t0)\n",
        "    t1 = self.tranformerblock_1(d0)\n",
        "    d1 = self.downsample_1(t1)\n",
        "    t2 = self.tranformerblock_2(d1)\n",
        "    d2 = self.downsample_2(t2)\n",
        "    t3 = self.tranformerblock_3(d2)\n",
        "    d3 = self.downsample_3(t3)\n",
        "\n",
        "\n",
        "    # bottleneck\n",
        "    t4 = self.tranformerblock_4(d3)\n",
        "\n",
        "\n",
        "    # decoder\n",
        "    u0 = self.upsample_0(t4)\n",
        "    # print(\"1) Upsampled in: \",u0.shape)\n",
        "    # print(\"1) Skipped in: \",t3.shape)\n",
        "    skippedconn_0 = torch.cat([u0, t3], -1) # this creates a skipped connection between t3 and t6 (u0 would have to be the input of t5)\n",
        "    t5 = self.tranformerblock_5(skippedconn_0)\n",
        "\n",
        "    u1 = self.upsample_1(t5)\n",
        "    # print(\"2) Upsampled in: \",u1.shape)\n",
        "    # print(\"2) Skipped in: \",t2.shape)\n",
        "    skippedconn_1 = torch.cat([u1, t2], -1)\n",
        "    t6 = self.tranformerblock_6(skippedconn_1)\n",
        "\n",
        "    u2 = self.upsample_2(t6)\n",
        "    # print(\"3) Upsampled in: \",u2.shape)\n",
        "    # print(\"3) Skipped in: \",t1.shape)\n",
        "    skippedconn_2 = torch.cat([u2, t1], -1)\n",
        "    t7 = self.tranformerblock_7(skippedconn_2)\n",
        "\n",
        "    u3 = self.upsample_3(t7)\n",
        "    # print(\"4) Upsampled in: \",u3.shape)\n",
        "    # print(\"4) Skipped in: \",t0.shape)\n",
        "    skippedconn_3 = torch.cat([u3, t0], -1)\n",
        "    t8 = self.tranformerblock_8(skippedconn_3)\n",
        "\n",
        "    residual = self.output_proj(t8)\n",
        "\n",
        "\n",
        "    # final residual summation\n",
        "    # print(\"Degraded: \",degraded_image.shape)\n",
        "    # print(\"Residual: \",residual.shape)\n",
        "    restored_image = degraded_image + residual\n",
        "\n",
        "    return restored_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hCfDRBKpV_y"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(device,model, optimizer,criterion,train_dataloader,test_dataloader):\n",
        "  # Globals\n",
        "  history = {'train_loss': [], 'val_loss': []}\n",
        "  train_loss_list = []\n",
        "  test_loss_list = []\n",
        "\n",
        "  if global_var['do_print_model']:\n",
        "    print_model(model, device, input_shape=[global_var['RGB_img_res'][0],global_var['patch_size'],global_var['patch_size']])\n",
        "    print('The {} model has: {} trainable parameters'.format(model_name, count_parameters(model)))\n",
        "\n",
        "  print(\"--- Start training: {} ---\\n\".format(model_name))\n",
        "  # Train\n",
        "\n",
        "  for epoch in range(global_var['epochs']):\n",
        "    iter = 1\n",
        "    model.train(mode=True)\n",
        "    running_loss = 0\n",
        "\n",
        "    with tqdm(train_dataloader, unit=\"step\", position=0, leave=True) as tepoch:\n",
        "      for batch in tepoch:\n",
        "        tepoch.set_description(f\"Epoch {epoch + 1}/{global_var['epochs']} - Training\")\n",
        "\n",
        "        # Load data\n",
        "        inputs, targets = batch[0].to(device=device), batch[1].to(device=device)\n",
        "\n",
        "        # Forward\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward\n",
        "        loss = torch.clone(loss).detach().requires_grad_(True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Evaluation and Stats\n",
        "        running_loss += loss.item()\n",
        "        train_loss_list.append(loss.item())\n",
        "\n",
        "        tepoch.set_postfix({'Loss': running_loss / iter})\n",
        "        iter += 1\n",
        "\n",
        "    # Validation\n",
        "    iter = 1\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with tqdm(test_dataloader, unit=\"step\", position=0, leave=True) as tepoch:\n",
        "      for batch in tepoch:\n",
        "        tepoch.set_description(f\"Epoch {epoch + 1}/{global_var['epochs']} - Validation\")\n",
        "        inputs, targets = batch[0].to(device=device), batch[1].to(device=device)\n",
        "\n",
        "        # Validation loop\n",
        "        with torch.no_grad():\n",
        "          outputs = model(inputs)\n",
        "\n",
        "          # Evaluation metrics\n",
        "\n",
        "          # Loss\n",
        "          loss = criterion(outputs, targets)\n",
        "          test_loss += loss.item()\n",
        "          test_loss_list.append(loss.item())\n",
        "\n",
        "          tepoch.set_postfix({'Loss': test_loss / iter})\n",
        "          iter += 1\n",
        "\n",
        "        # Update history infos\n",
        "        history['train_loss'].append(running_loss / len(train_dataloader))\n",
        "        history['val_loss'].append(test_loss / len(test_dataloader))\n",
        "\n",
        "        save_history(history, save_model_root + model_name + '_history')\n",
        "        save_checkpoint(model, model_name + '_best_acc')\n",
        "        # Empty CUDA cache\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Save loss for graphs\n",
        "        np.save(save_model_root + 'train.npy', np.array(train_loss_list))\n",
        "        np.save(save_model_root + 'test.npy', np.array(test_loss_list))\n",
        "\n",
        "  print('--- Finished Training ---')\n",
        "  # save_csv_history(model_name=model_name)\n",
        "  # plot_history(history)\n",
        "  # plot_loss(history, title='Loss Trend')\n",
        "\n",
        "  return history,train_loss_list, test_loss_list"
      ],
      "metadata": {
        "id": "dpjv-6_BqAH7"
      },
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZQvL4hihzUer",
        "outputId": "e37b5239-9f93-4b96-fec9-5e575c0154a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual device:  cuda:0\n",
            "=======================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: The default value of numeric_only in DataFrame.sum is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  df_sum = df.sum()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   Kernel Shape  \\\n",
            "Layer                                                             \n",
            "0_input_proj.proj.Conv2d_0                        [3, 32, 3, 3]   \n",
            "1_input_proj.proj.LeakyReLU_1                                 -   \n",
            "2_tranformerblock_0.LayerNorm_norm1                        [32]   \n",
            "3_tranformerblock_0.Dropout_dropout                           -   \n",
            "4_tranformerblock_0.w_msa.Linear_qkv                   [32, 96]   \n",
            "5_tranformerblock_0.w_msa.Dropout_attn_drop                   -   \n",
            "6_tranformerblock_0.w_msa.Linear_qkv                   [32, 96]   \n",
            "7_tranformerblock_0.w_msa.Dropout_attn_drop                   -   \n",
            "8_tranformerblock_0.w_msa.Linear_proj                  [32, 32]   \n",
            "9_tranformerblock_0.w_msa.Dropout_proj_drop                   -   \n",
            "10_tranformerblock_0.LayerNorm_norm2                       [32]   \n",
            "11_tranformerblock_0.Dropout_dropout                          -   \n",
            "12_tranformerblock_0.leff.layer1.Linear_0             [32, 128]   \n",
            "13_tranformerblock_0.leff.layer1.GELU_1                       -   \n",
            "14_tranformerblock_0.leff.layer2.Conv2d_0      [128, 128, 3, 3]   \n",
            "15_tranformerblock_0.leff.layer2.GELU_1                       -   \n",
            "16_tranformerblock_0.leff.layer3.Linear_0             [128, 32]   \n",
            "17_downsample_0.conv.Conv2d_0                    [32, 64, 4, 4]   \n",
            "18_tranformerblock_1.LayerNorm_norm1                       [64]   \n",
            "19_tranformerblock_1.Dropout_dropout                          -   \n",
            "20_tranformerblock_1.w_msa.Linear_qkv                 [64, 192]   \n",
            "21_tranformerblock_1.w_msa.Dropout_attn_drop                  -   \n",
            "22_tranformerblock_1.w_msa.Linear_qkv                 [64, 192]   \n",
            "23_tranformerblock_1.w_msa.Dropout_attn_drop                  -   \n",
            "24_tranformerblock_1.w_msa.Linear_proj                 [64, 64]   \n",
            "25_tranformerblock_1.w_msa.Dropout_proj_drop                  -   \n",
            "26_tranformerblock_1.LayerNorm_norm2                       [64]   \n",
            "27_tranformerblock_1.Dropout_dropout                          -   \n",
            "28_tranformerblock_1.leff.layer1.Linear_0             [64, 128]   \n",
            "29_tranformerblock_1.leff.layer1.GELU_1                       -   \n",
            "30_tranformerblock_1.leff.layer2.Conv2d_0      [128, 128, 3, 3]   \n",
            "31_tranformerblock_1.leff.layer2.GELU_1                       -   \n",
            "32_tranformerblock_1.leff.layer3.Linear_0             [128, 64]   \n",
            "33_downsample_1.conv.Conv2d_0                   [64, 128, 4, 4]   \n",
            "34_tranformerblock_2.LayerNorm_norm1                      [128]   \n",
            "35_tranformerblock_2.Dropout_dropout                          -   \n",
            "36_tranformerblock_2.w_msa.Linear_qkv                [128, 384]   \n",
            "37_tranformerblock_2.w_msa.Dropout_attn_drop                  -   \n",
            "38_tranformerblock_2.w_msa.Linear_qkv                [128, 384]   \n",
            "39_tranformerblock_2.w_msa.Dropout_attn_drop                  -   \n",
            "40_tranformerblock_2.w_msa.Linear_proj               [128, 128]   \n",
            "41_tranformerblock_2.w_msa.Dropout_proj_drop                  -   \n",
            "42_tranformerblock_2.LayerNorm_norm2                      [128]   \n",
            "43_tranformerblock_2.Dropout_dropout                          -   \n",
            "44_tranformerblock_2.leff.layer1.Linear_0            [128, 128]   \n",
            "45_tranformerblock_2.leff.layer1.GELU_1                       -   \n",
            "46_tranformerblock_2.leff.layer2.Conv2d_0      [128, 128, 3, 3]   \n",
            "47_tranformerblock_2.leff.layer2.GELU_1                       -   \n",
            "48_tranformerblock_2.leff.layer3.Linear_0            [128, 128]   \n",
            "49_downsample_2.conv.Conv2d_0                  [128, 256, 4, 4]   \n",
            "50_tranformerblock_3.LayerNorm_norm1                      [256]   \n",
            "51_tranformerblock_3.Dropout_dropout                          -   \n",
            "52_tranformerblock_3.w_msa.Linear_qkv                [256, 768]   \n",
            "53_tranformerblock_3.w_msa.Dropout_attn_drop                  -   \n",
            "54_tranformerblock_3.w_msa.Linear_qkv                [256, 768]   \n",
            "55_tranformerblock_3.w_msa.Dropout_attn_drop                  -   \n",
            "56_tranformerblock_3.w_msa.Linear_proj               [256, 256]   \n",
            "57_tranformerblock_3.w_msa.Dropout_proj_drop                  -   \n",
            "58_tranformerblock_3.LayerNorm_norm2                      [256]   \n",
            "59_tranformerblock_3.Dropout_dropout                          -   \n",
            "60_tranformerblock_3.leff.layer1.Linear_0            [256, 128]   \n",
            "61_tranformerblock_3.leff.layer1.GELU_1                       -   \n",
            "62_tranformerblock_3.leff.layer2.Conv2d_0      [128, 128, 3, 3]   \n",
            "63_tranformerblock_3.leff.layer2.GELU_1                       -   \n",
            "64_tranformerblock_3.leff.layer3.Linear_0            [128, 256]   \n",
            "65_downsample_3.conv.Conv2d_0                  [256, 512, 4, 4]   \n",
            "66_tranformerblock_4.LayerNorm_norm1                      [512]   \n",
            "67_tranformerblock_4.Dropout_dropout                          -   \n",
            "68_tranformerblock_4.w_msa.Linear_qkv               [512, 1536]   \n",
            "69_tranformerblock_4.w_msa.Dropout_attn_drop                  -   \n",
            "70_tranformerblock_4.w_msa.Linear_qkv               [512, 1536]   \n",
            "71_tranformerblock_4.w_msa.Dropout_attn_drop                  -   \n",
            "72_tranformerblock_4.w_msa.Linear_proj               [512, 512]   \n",
            "73_tranformerblock_4.w_msa.Dropout_proj_drop                  -   \n",
            "74_tranformerblock_4.LayerNorm_norm2                      [512]   \n",
            "75_tranformerblock_4.Dropout_dropout                          -   \n",
            "76_tranformerblock_4.leff.layer1.Linear_0            [512, 128]   \n",
            "77_tranformerblock_4.leff.layer1.GELU_1                       -   \n",
            "78_tranformerblock_4.leff.layer2.Conv2d_0      [128, 128, 3, 3]   \n",
            "79_tranformerblock_4.leff.layer2.GELU_1                       -   \n",
            "80_tranformerblock_4.leff.layer3.Linear_0            [128, 512]   \n",
            "81_upsample_0.deconv.ConvTranspose2d_0         [256, 512, 2, 2]   \n",
            "82_tranformerblock_5.LayerNorm_norm1                      [512]   \n",
            "83_tranformerblock_5.Dropout_dropout                          -   \n",
            "84_tranformerblock_5.w_msa.Linear_qkv               [512, 1536]   \n",
            "85_tranformerblock_5.w_msa.Dropout_attn_drop                  -   \n",
            "86_tranformerblock_5.w_msa.Linear_qkv               [512, 1536]   \n",
            "87_tranformerblock_5.w_msa.Dropout_attn_drop                  -   \n",
            "88_tranformerblock_5.w_msa.Linear_proj               [512, 512]   \n",
            "89_tranformerblock_5.w_msa.Dropout_proj_drop                  -   \n",
            "90_tranformerblock_5.LayerNorm_norm2                      [512]   \n",
            "91_tranformerblock_5.Dropout_dropout                          -   \n",
            "92_tranformerblock_5.leff.layer1.Linear_0            [512, 128]   \n",
            "93_tranformerblock_5.leff.layer1.GELU_1                       -   \n",
            "94_tranformerblock_5.leff.layer2.Conv2d_0      [128, 128, 3, 3]   \n",
            "95_tranformerblock_5.leff.layer2.GELU_1                       -   \n",
            "96_tranformerblock_5.leff.layer3.Linear_0            [128, 512]   \n",
            "97_upsample_1.deconv.ConvTranspose2d_0         [128, 512, 2, 2]   \n",
            "98_tranformerblock_6.LayerNorm_norm1                      [256]   \n",
            "99_tranformerblock_6.Dropout_dropout                          -   \n",
            "100_tranformerblock_6.w_msa.Linear_qkv               [256, 768]   \n",
            "101_tranformerblock_6.w_msa.Dropout_attn_drop                 -   \n",
            "102_tranformerblock_6.w_msa.Linear_qkv               [256, 768]   \n",
            "103_tranformerblock_6.w_msa.Dropout_attn_drop                 -   \n",
            "104_tranformerblock_6.w_msa.Linear_proj              [256, 256]   \n",
            "105_tranformerblock_6.w_msa.Dropout_proj_drop                 -   \n",
            "106_tranformerblock_6.LayerNorm_norm2                     [256]   \n",
            "107_tranformerblock_6.Dropout_dropout                         -   \n",
            "108_tranformerblock_6.leff.layer1.Linear_0           [256, 128]   \n",
            "109_tranformerblock_6.leff.layer1.GELU_1                      -   \n",
            "110_tranformerblock_6.leff.layer2.Conv2d_0     [128, 128, 3, 3]   \n",
            "111_tranformerblock_6.leff.layer2.GELU_1                      -   \n",
            "112_tranformerblock_6.leff.layer3.Linear_0           [128, 256]   \n",
            "113_upsample_2.deconv.ConvTranspose2d_0         [64, 256, 2, 2]   \n",
            "114_tranformerblock_7.LayerNorm_norm1                     [128]   \n",
            "115_tranformerblock_7.Dropout_dropout                         -   \n",
            "116_tranformerblock_7.w_msa.Linear_qkv               [128, 384]   \n",
            "117_tranformerblock_7.w_msa.Dropout_attn_drop                 -   \n",
            "118_tranformerblock_7.w_msa.Linear_qkv               [128, 384]   \n",
            "119_tranformerblock_7.w_msa.Dropout_attn_drop                 -   \n",
            "120_tranformerblock_7.w_msa.Linear_proj              [128, 128]   \n",
            "121_tranformerblock_7.w_msa.Dropout_proj_drop                 -   \n",
            "122_tranformerblock_7.LayerNorm_norm2                     [128]   \n",
            "123_tranformerblock_7.Dropout_dropout                         -   \n",
            "124_tranformerblock_7.leff.layer1.Linear_0           [128, 128]   \n",
            "125_tranformerblock_7.leff.layer1.GELU_1                      -   \n",
            "126_tranformerblock_7.leff.layer2.Conv2d_0     [128, 128, 3, 3]   \n",
            "127_tranformerblock_7.leff.layer2.GELU_1                      -   \n",
            "128_tranformerblock_7.leff.layer3.Linear_0           [128, 128]   \n",
            "129_upsample_3.deconv.ConvTranspose2d_0         [32, 128, 2, 2]   \n",
            "130_tranformerblock_8.LayerNorm_norm1                      [64]   \n",
            "131_tranformerblock_8.Dropout_dropout                         -   \n",
            "132_tranformerblock_8.w_msa.Linear_qkv                [64, 192]   \n",
            "133_tranformerblock_8.w_msa.Dropout_attn_drop                 -   \n",
            "134_tranformerblock_8.w_msa.Linear_qkv                [64, 192]   \n",
            "135_tranformerblock_8.w_msa.Dropout_attn_drop                 -   \n",
            "136_tranformerblock_8.w_msa.Linear_proj                [64, 64]   \n",
            "137_tranformerblock_8.w_msa.Dropout_proj_drop                 -   \n",
            "138_tranformerblock_8.LayerNorm_norm2                      [64]   \n",
            "139_tranformerblock_8.Dropout_dropout                         -   \n",
            "140_tranformerblock_8.leff.layer1.Linear_0            [64, 128]   \n",
            "141_tranformerblock_8.leff.layer1.GELU_1                      -   \n",
            "142_tranformerblock_8.leff.layer2.Conv2d_0     [128, 128, 3, 3]   \n",
            "143_tranformerblock_8.leff.layer2.GELU_1                      -   \n",
            "144_tranformerblock_8.leff.layer3.Linear_0            [128, 64]   \n",
            "145_output_proj.proj.Conv2d_0                     [64, 3, 3, 3]   \n",
            "146_output_proj.proj.LeakyReLU_1                              -   \n",
            "\n",
            "                                                  Output Shape     Params  \\\n",
            "Layer                                                                       \n",
            "0_input_proj.proj.Conv2d_0                     [8, 32, 32, 32]      896.0   \n",
            "1_input_proj.proj.LeakyReLU_1                  [8, 32, 32, 32]          -   \n",
            "2_tranformerblock_0.LayerNorm_norm1              [8, 1024, 32]       64.0   \n",
            "3_tranformerblock_0.Dropout_dropout              [8, 1024, 32]          -   \n",
            "4_tranformerblock_0.w_msa.Linear_qkv             [4, 1024, 96]     3.072k   \n",
            "5_tranformerblock_0.w_msa.Dropout_attn_drop      [8, 512, 512]          -   \n",
            "6_tranformerblock_0.w_msa.Linear_qkv             [4, 1024, 96]          -   \n",
            "7_tranformerblock_0.w_msa.Dropout_attn_drop      [8, 512, 512]          -   \n",
            "8_tranformerblock_0.w_msa.Linear_proj            [8, 1024, 32]     1.056k   \n",
            "9_tranformerblock_0.w_msa.Dropout_proj_drop      [8, 1024, 32]          -   \n",
            "10_tranformerblock_0.LayerNorm_norm2             [8, 1024, 32]       64.0   \n",
            "11_tranformerblock_0.Dropout_dropout             [8, 1024, 32]          -   \n",
            "12_tranformerblock_0.leff.layer1.Linear_0       [8, 1024, 128]     4.224k   \n",
            "13_tranformerblock_0.leff.layer1.GELU_1         [8, 1024, 128]          -   \n",
            "14_tranformerblock_0.leff.layer2.Conv2d_0       [128, 1024, 8]   147.584k   \n",
            "15_tranformerblock_0.leff.layer2.GELU_1         [128, 1024, 8]          -   \n",
            "16_tranformerblock_0.leff.layer3.Linear_0        [8, 1024, 32]     4.128k   \n",
            "17_downsample_0.conv.Conv2d_0                  [8, 64, 16, 16]    32.832k   \n",
            "18_tranformerblock_1.LayerNorm_norm1              [8, 256, 64]      128.0   \n",
            "19_tranformerblock_1.Dropout_dropout              [8, 256, 64]          -   \n",
            "20_tranformerblock_1.w_msa.Linear_qkv            [4, 256, 192]    12.288k   \n",
            "21_tranformerblock_1.w_msa.Dropout_attn_drop     [8, 256, 256]          -   \n",
            "22_tranformerblock_1.w_msa.Linear_qkv            [4, 256, 192]          -   \n",
            "23_tranformerblock_1.w_msa.Dropout_attn_drop     [8, 256, 256]          -   \n",
            "24_tranformerblock_1.w_msa.Linear_proj            [8, 256, 64]      4.16k   \n",
            "25_tranformerblock_1.w_msa.Dropout_proj_drop      [8, 256, 64]          -   \n",
            "26_tranformerblock_1.LayerNorm_norm2              [8, 256, 64]      128.0   \n",
            "27_tranformerblock_1.Dropout_dropout              [8, 256, 64]          -   \n",
            "28_tranformerblock_1.leff.layer1.Linear_0        [8, 256, 128]      8.32k   \n",
            "29_tranformerblock_1.leff.layer1.GELU_1          [8, 256, 128]          -   \n",
            "30_tranformerblock_1.leff.layer2.Conv2d_0        [128, 256, 8]   147.584k   \n",
            "31_tranformerblock_1.leff.layer2.GELU_1          [128, 256, 8]          -   \n",
            "32_tranformerblock_1.leff.layer3.Linear_0         [8, 256, 64]     8.256k   \n",
            "33_downsample_1.conv.Conv2d_0                   [8, 128, 8, 8]     131.2k   \n",
            "34_tranformerblock_2.LayerNorm_norm1              [8, 64, 128]      256.0   \n",
            "35_tranformerblock_2.Dropout_dropout              [8, 64, 128]          -   \n",
            "36_tranformerblock_2.w_msa.Linear_qkv             [4, 64, 384]    49.152k   \n",
            "37_tranformerblock_2.w_msa.Dropout_attn_drop     [8, 128, 128]          -   \n",
            "38_tranformerblock_2.w_msa.Linear_qkv             [4, 64, 384]          -   \n",
            "39_tranformerblock_2.w_msa.Dropout_attn_drop     [8, 128, 128]          -   \n",
            "40_tranformerblock_2.w_msa.Linear_proj            [8, 64, 128]    16.512k   \n",
            "41_tranformerblock_2.w_msa.Dropout_proj_drop      [8, 64, 128]          -   \n",
            "42_tranformerblock_2.LayerNorm_norm2              [8, 64, 128]      256.0   \n",
            "43_tranformerblock_2.Dropout_dropout              [8, 64, 128]          -   \n",
            "44_tranformerblock_2.leff.layer1.Linear_0         [8, 64, 128]    16.512k   \n",
            "45_tranformerblock_2.leff.layer1.GELU_1           [8, 64, 128]          -   \n",
            "46_tranformerblock_2.leff.layer2.Conv2d_0         [128, 64, 8]   147.584k   \n",
            "47_tranformerblock_2.leff.layer2.GELU_1           [128, 64, 8]          -   \n",
            "48_tranformerblock_2.leff.layer3.Linear_0         [8, 64, 128]    16.512k   \n",
            "49_downsample_2.conv.Conv2d_0                   [8, 256, 4, 4]   524.544k   \n",
            "50_tranformerblock_3.LayerNorm_norm1              [8, 16, 256]      512.0   \n",
            "51_tranformerblock_3.Dropout_dropout              [8, 16, 256]          -   \n",
            "52_tranformerblock_3.w_msa.Linear_qkv             [4, 16, 768]   196.608k   \n",
            "53_tranformerblock_3.w_msa.Dropout_attn_drop       [8, 64, 64]          -   \n",
            "54_tranformerblock_3.w_msa.Linear_qkv             [4, 16, 768]          -   \n",
            "55_tranformerblock_3.w_msa.Dropout_attn_drop       [8, 64, 64]          -   \n",
            "56_tranformerblock_3.w_msa.Linear_proj            [8, 16, 256]    65.792k   \n",
            "57_tranformerblock_3.w_msa.Dropout_proj_drop      [8, 16, 256]          -   \n",
            "58_tranformerblock_3.LayerNorm_norm2              [8, 16, 256]      512.0   \n",
            "59_tranformerblock_3.Dropout_dropout              [8, 16, 256]          -   \n",
            "60_tranformerblock_3.leff.layer1.Linear_0         [8, 16, 128]    32.896k   \n",
            "61_tranformerblock_3.leff.layer1.GELU_1           [8, 16, 128]          -   \n",
            "62_tranformerblock_3.leff.layer2.Conv2d_0         [128, 16, 8]   147.584k   \n",
            "63_tranformerblock_3.leff.layer2.GELU_1           [128, 16, 8]          -   \n",
            "64_tranformerblock_3.leff.layer3.Linear_0         [8, 16, 256]    33.024k   \n",
            "65_downsample_3.conv.Conv2d_0                   [8, 512, 2, 2]  2.097664M   \n",
            "66_tranformerblock_4.LayerNorm_norm1               [8, 4, 512]     1.024k   \n",
            "67_tranformerblock_4.Dropout_dropout               [8, 4, 512]          -   \n",
            "68_tranformerblock_4.w_msa.Linear_qkv             [4, 4, 1536]   786.432k   \n",
            "69_tranformerblock_4.w_msa.Dropout_attn_drop       [8, 32, 32]          -   \n",
            "70_tranformerblock_4.w_msa.Linear_qkv             [4, 4, 1536]          -   \n",
            "71_tranformerblock_4.w_msa.Dropout_attn_drop       [8, 32, 32]          -   \n",
            "72_tranformerblock_4.w_msa.Linear_proj             [8, 4, 512]   262.656k   \n",
            "73_tranformerblock_4.w_msa.Dropout_proj_drop       [8, 4, 512]          -   \n",
            "74_tranformerblock_4.LayerNorm_norm2               [8, 4, 512]     1.024k   \n",
            "75_tranformerblock_4.Dropout_dropout               [8, 4, 512]          -   \n",
            "76_tranformerblock_4.leff.layer1.Linear_0          [8, 4, 128]    65.664k   \n",
            "77_tranformerblock_4.leff.layer1.GELU_1            [8, 4, 128]          -   \n",
            "78_tranformerblock_4.leff.layer2.Conv2d_0          [128, 4, 8]   147.584k   \n",
            "79_tranformerblock_4.leff.layer2.GELU_1            [128, 4, 8]          -   \n",
            "80_tranformerblock_4.leff.layer3.Linear_0          [8, 4, 512]    66.048k   \n",
            "81_upsample_0.deconv.ConvTranspose2d_0          [8, 256, 4, 4]   524.544k   \n",
            "82_tranformerblock_5.LayerNorm_norm1              [8, 16, 512]     1.024k   \n",
            "83_tranformerblock_5.Dropout_dropout              [8, 16, 512]          -   \n",
            "84_tranformerblock_5.w_msa.Linear_qkv            [4, 16, 1536]   786.432k   \n",
            "85_tranformerblock_5.w_msa.Dropout_attn_drop     [8, 128, 128]          -   \n",
            "86_tranformerblock_5.w_msa.Linear_qkv            [4, 16, 1536]          -   \n",
            "87_tranformerblock_5.w_msa.Dropout_attn_drop     [8, 128, 128]          -   \n",
            "88_tranformerblock_5.w_msa.Linear_proj            [8, 16, 512]   262.656k   \n",
            "89_tranformerblock_5.w_msa.Dropout_proj_drop      [8, 16, 512]          -   \n",
            "90_tranformerblock_5.LayerNorm_norm2              [8, 16, 512]     1.024k   \n",
            "91_tranformerblock_5.Dropout_dropout              [8, 16, 512]          -   \n",
            "92_tranformerblock_5.leff.layer1.Linear_0         [8, 16, 128]    65.664k   \n",
            "93_tranformerblock_5.leff.layer1.GELU_1           [8, 16, 128]          -   \n",
            "94_tranformerblock_5.leff.layer2.Conv2d_0         [128, 16, 8]   147.584k   \n",
            "95_tranformerblock_5.leff.layer2.GELU_1           [128, 16, 8]          -   \n",
            "96_tranformerblock_5.leff.layer3.Linear_0         [8, 16, 512]    66.048k   \n",
            "97_upsample_1.deconv.ConvTranspose2d_0          [8, 128, 8, 8]   262.272k   \n",
            "98_tranformerblock_6.LayerNorm_norm1              [8, 64, 256]      512.0   \n",
            "99_tranformerblock_6.Dropout_dropout              [8, 64, 256]          -   \n",
            "100_tranformerblock_6.w_msa.Linear_qkv            [4, 64, 768]   196.608k   \n",
            "101_tranformerblock_6.w_msa.Dropout_attn_drop    [8, 256, 256]          -   \n",
            "102_tranformerblock_6.w_msa.Linear_qkv            [4, 64, 768]          -   \n",
            "103_tranformerblock_6.w_msa.Dropout_attn_drop    [8, 256, 256]          -   \n",
            "104_tranformerblock_6.w_msa.Linear_proj           [8, 64, 256]    65.792k   \n",
            "105_tranformerblock_6.w_msa.Dropout_proj_drop     [8, 64, 256]          -   \n",
            "106_tranformerblock_6.LayerNorm_norm2             [8, 64, 256]      512.0   \n",
            "107_tranformerblock_6.Dropout_dropout             [8, 64, 256]          -   \n",
            "108_tranformerblock_6.leff.layer1.Linear_0        [8, 64, 128]    32.896k   \n",
            "109_tranformerblock_6.leff.layer1.GELU_1          [8, 64, 128]          -   \n",
            "110_tranformerblock_6.leff.layer2.Conv2d_0        [128, 64, 8]   147.584k   \n",
            "111_tranformerblock_6.leff.layer2.GELU_1          [128, 64, 8]          -   \n",
            "112_tranformerblock_6.leff.layer3.Linear_0        [8, 64, 256]    33.024k   \n",
            "113_upsample_2.deconv.ConvTranspose2d_0        [8, 64, 16, 16]      65.6k   \n",
            "114_tranformerblock_7.LayerNorm_norm1            [8, 256, 128]      256.0   \n",
            "115_tranformerblock_7.Dropout_dropout            [8, 256, 128]          -   \n",
            "116_tranformerblock_7.w_msa.Linear_qkv           [4, 256, 384]    49.152k   \n",
            "117_tranformerblock_7.w_msa.Dropout_attn_drop    [8, 512, 512]          -   \n",
            "118_tranformerblock_7.w_msa.Linear_qkv           [4, 256, 384]          -   \n",
            "119_tranformerblock_7.w_msa.Dropout_attn_drop    [8, 512, 512]          -   \n",
            "120_tranformerblock_7.w_msa.Linear_proj          [8, 256, 128]    16.512k   \n",
            "121_tranformerblock_7.w_msa.Dropout_proj_drop    [8, 256, 128]          -   \n",
            "122_tranformerblock_7.LayerNorm_norm2            [8, 256, 128]      256.0   \n",
            "123_tranformerblock_7.Dropout_dropout            [8, 256, 128]          -   \n",
            "124_tranformerblock_7.leff.layer1.Linear_0       [8, 256, 128]    16.512k   \n",
            "125_tranformerblock_7.leff.layer1.GELU_1         [8, 256, 128]          -   \n",
            "126_tranformerblock_7.leff.layer2.Conv2d_0       [128, 256, 8]   147.584k   \n",
            "127_tranformerblock_7.leff.layer2.GELU_1         [128, 256, 8]          -   \n",
            "128_tranformerblock_7.leff.layer3.Linear_0       [8, 256, 128]    16.512k   \n",
            "129_upsample_3.deconv.ConvTranspose2d_0        [8, 32, 32, 32]    16.416k   \n",
            "130_tranformerblock_8.LayerNorm_norm1            [8, 1024, 64]      128.0   \n",
            "131_tranformerblock_8.Dropout_dropout            [8, 1024, 64]          -   \n",
            "132_tranformerblock_8.w_msa.Linear_qkv          [4, 1024, 192]    12.288k   \n",
            "133_tranformerblock_8.w_msa.Dropout_attn_drop  [8, 1024, 1024]          -   \n",
            "134_tranformerblock_8.w_msa.Linear_qkv          [4, 1024, 192]          -   \n",
            "135_tranformerblock_8.w_msa.Dropout_attn_drop  [8, 1024, 1024]          -   \n",
            "136_tranformerblock_8.w_msa.Linear_proj          [8, 1024, 64]      4.16k   \n",
            "137_tranformerblock_8.w_msa.Dropout_proj_drop    [8, 1024, 64]          -   \n",
            "138_tranformerblock_8.LayerNorm_norm2            [8, 1024, 64]      128.0   \n",
            "139_tranformerblock_8.Dropout_dropout            [8, 1024, 64]          -   \n",
            "140_tranformerblock_8.leff.layer1.Linear_0      [8, 1024, 128]      8.32k   \n",
            "141_tranformerblock_8.leff.layer1.GELU_1        [8, 1024, 128]          -   \n",
            "142_tranformerblock_8.leff.layer2.Conv2d_0      [128, 1024, 8]   147.584k   \n",
            "143_tranformerblock_8.leff.layer2.GELU_1        [128, 1024, 8]          -   \n",
            "144_tranformerblock_8.leff.layer3.Linear_0       [8, 1024, 64]     8.256k   \n",
            "145_output_proj.proj.Conv2d_0                   [8, 3, 32, 32]     1.731k   \n",
            "146_output_proj.proj.LeakyReLU_1                [8, 3, 32, 32]          -   \n",
            "\n",
            "                                                Mult-Adds  \n",
            "Layer                                                      \n",
            "0_input_proj.proj.Conv2d_0                       884.736k  \n",
            "1_input_proj.proj.LeakyReLU_1                           -  \n",
            "2_tranformerblock_0.LayerNorm_norm1                  32.0  \n",
            "3_tranformerblock_0.Dropout_dropout                     -  \n",
            "4_tranformerblock_0.w_msa.Linear_qkv               3.072k  \n",
            "5_tranformerblock_0.w_msa.Dropout_attn_drop             -  \n",
            "6_tranformerblock_0.w_msa.Linear_qkv               3.072k  \n",
            "7_tranformerblock_0.w_msa.Dropout_attn_drop             -  \n",
            "8_tranformerblock_0.w_msa.Linear_proj              1.024k  \n",
            "9_tranformerblock_0.w_msa.Dropout_proj_drop             -  \n",
            "10_tranformerblock_0.LayerNorm_norm2                 32.0  \n",
            "11_tranformerblock_0.Dropout_dropout                    -  \n",
            "12_tranformerblock_0.leff.layer1.Linear_0          4.096k  \n",
            "13_tranformerblock_0.leff.layer1.GELU_1                 -  \n",
            "14_tranformerblock_0.leff.layer2.Conv2d_0       1.179648M  \n",
            "15_tranformerblock_0.leff.layer2.GELU_1                 -  \n",
            "16_tranformerblock_0.leff.layer3.Linear_0          4.096k  \n",
            "17_downsample_0.conv.Conv2d_0                   8.388608M  \n",
            "18_tranformerblock_1.LayerNorm_norm1                 64.0  \n",
            "19_tranformerblock_1.Dropout_dropout                    -  \n",
            "20_tranformerblock_1.w_msa.Linear_qkv             12.288k  \n",
            "21_tranformerblock_1.w_msa.Dropout_attn_drop            -  \n",
            "22_tranformerblock_1.w_msa.Linear_qkv             12.288k  \n",
            "23_tranformerblock_1.w_msa.Dropout_attn_drop            -  \n",
            "24_tranformerblock_1.w_msa.Linear_proj             4.096k  \n",
            "25_tranformerblock_1.w_msa.Dropout_proj_drop            -  \n",
            "26_tranformerblock_1.LayerNorm_norm2                 64.0  \n",
            "27_tranformerblock_1.Dropout_dropout                    -  \n",
            "28_tranformerblock_1.leff.layer1.Linear_0          8.192k  \n",
            "29_tranformerblock_1.leff.layer1.GELU_1                 -  \n",
            "30_tranformerblock_1.leff.layer2.Conv2d_0       1.179648M  \n",
            "31_tranformerblock_1.leff.layer2.GELU_1                 -  \n",
            "32_tranformerblock_1.leff.layer3.Linear_0          8.192k  \n",
            "33_downsample_1.conv.Conv2d_0                   8.388608M  \n",
            "34_tranformerblock_2.LayerNorm_norm1                128.0  \n",
            "35_tranformerblock_2.Dropout_dropout                    -  \n",
            "36_tranformerblock_2.w_msa.Linear_qkv             49.152k  \n",
            "37_tranformerblock_2.w_msa.Dropout_attn_drop            -  \n",
            "38_tranformerblock_2.w_msa.Linear_qkv             49.152k  \n",
            "39_tranformerblock_2.w_msa.Dropout_attn_drop            -  \n",
            "40_tranformerblock_2.w_msa.Linear_proj            16.384k  \n",
            "41_tranformerblock_2.w_msa.Dropout_proj_drop            -  \n",
            "42_tranformerblock_2.LayerNorm_norm2                128.0  \n",
            "43_tranformerblock_2.Dropout_dropout                    -  \n",
            "44_tranformerblock_2.leff.layer1.Linear_0         16.384k  \n",
            "45_tranformerblock_2.leff.layer1.GELU_1                 -  \n",
            "46_tranformerblock_2.leff.layer2.Conv2d_0       1.179648M  \n",
            "47_tranformerblock_2.leff.layer2.GELU_1                 -  \n",
            "48_tranformerblock_2.leff.layer3.Linear_0         16.384k  \n",
            "49_downsample_2.conv.Conv2d_0                   8.388608M  \n",
            "50_tranformerblock_3.LayerNorm_norm1                256.0  \n",
            "51_tranformerblock_3.Dropout_dropout                    -  \n",
            "52_tranformerblock_3.w_msa.Linear_qkv            196.608k  \n",
            "53_tranformerblock_3.w_msa.Dropout_attn_drop            -  \n",
            "54_tranformerblock_3.w_msa.Linear_qkv            196.608k  \n",
            "55_tranformerblock_3.w_msa.Dropout_attn_drop            -  \n",
            "56_tranformerblock_3.w_msa.Linear_proj            65.536k  \n",
            "57_tranformerblock_3.w_msa.Dropout_proj_drop            -  \n",
            "58_tranformerblock_3.LayerNorm_norm2                256.0  \n",
            "59_tranformerblock_3.Dropout_dropout                    -  \n",
            "60_tranformerblock_3.leff.layer1.Linear_0         32.768k  \n",
            "61_tranformerblock_3.leff.layer1.GELU_1                 -  \n",
            "62_tranformerblock_3.leff.layer2.Conv2d_0       1.179648M  \n",
            "63_tranformerblock_3.leff.layer2.GELU_1                 -  \n",
            "64_tranformerblock_3.leff.layer3.Linear_0         32.768k  \n",
            "65_downsample_3.conv.Conv2d_0                   8.388608M  \n",
            "66_tranformerblock_4.LayerNorm_norm1                512.0  \n",
            "67_tranformerblock_4.Dropout_dropout                    -  \n",
            "68_tranformerblock_4.w_msa.Linear_qkv            786.432k  \n",
            "69_tranformerblock_4.w_msa.Dropout_attn_drop            -  \n",
            "70_tranformerblock_4.w_msa.Linear_qkv            786.432k  \n",
            "71_tranformerblock_4.w_msa.Dropout_attn_drop            -  \n",
            "72_tranformerblock_4.w_msa.Linear_proj           262.144k  \n",
            "73_tranformerblock_4.w_msa.Dropout_proj_drop            -  \n",
            "74_tranformerblock_4.LayerNorm_norm2                512.0  \n",
            "75_tranformerblock_4.Dropout_dropout                    -  \n",
            "76_tranformerblock_4.leff.layer1.Linear_0         65.536k  \n",
            "77_tranformerblock_4.leff.layer1.GELU_1                 -  \n",
            "78_tranformerblock_4.leff.layer2.Conv2d_0       1.179648M  \n",
            "79_tranformerblock_4.leff.layer2.GELU_1                 -  \n",
            "80_tranformerblock_4.leff.layer3.Linear_0         65.536k  \n",
            "81_upsample_0.deconv.ConvTranspose2d_0          8.388608M  \n",
            "82_tranformerblock_5.LayerNorm_norm1                512.0  \n",
            "83_tranformerblock_5.Dropout_dropout                    -  \n",
            "84_tranformerblock_5.w_msa.Linear_qkv            786.432k  \n",
            "85_tranformerblock_5.w_msa.Dropout_attn_drop            -  \n",
            "86_tranformerblock_5.w_msa.Linear_qkv            786.432k  \n",
            "87_tranformerblock_5.w_msa.Dropout_attn_drop            -  \n",
            "88_tranformerblock_5.w_msa.Linear_proj           262.144k  \n",
            "89_tranformerblock_5.w_msa.Dropout_proj_drop            -  \n",
            "90_tranformerblock_5.LayerNorm_norm2                512.0  \n",
            "91_tranformerblock_5.Dropout_dropout                    -  \n",
            "92_tranformerblock_5.leff.layer1.Linear_0         65.536k  \n",
            "93_tranformerblock_5.leff.layer1.GELU_1                 -  \n",
            "94_tranformerblock_5.leff.layer2.Conv2d_0       1.179648M  \n",
            "95_tranformerblock_5.leff.layer2.GELU_1                 -  \n",
            "96_tranformerblock_5.leff.layer3.Linear_0         65.536k  \n",
            "97_upsample_1.deconv.ConvTranspose2d_0         16.777216M  \n",
            "98_tranformerblock_6.LayerNorm_norm1                256.0  \n",
            "99_tranformerblock_6.Dropout_dropout                    -  \n",
            "100_tranformerblock_6.w_msa.Linear_qkv           196.608k  \n",
            "101_tranformerblock_6.w_msa.Dropout_attn_drop           -  \n",
            "102_tranformerblock_6.w_msa.Linear_qkv           196.608k  \n",
            "103_tranformerblock_6.w_msa.Dropout_attn_drop           -  \n",
            "104_tranformerblock_6.w_msa.Linear_proj           65.536k  \n",
            "105_tranformerblock_6.w_msa.Dropout_proj_drop           -  \n",
            "106_tranformerblock_6.LayerNorm_norm2               256.0  \n",
            "107_tranformerblock_6.Dropout_dropout                   -  \n",
            "108_tranformerblock_6.leff.layer1.Linear_0        32.768k  \n",
            "109_tranformerblock_6.leff.layer1.GELU_1                -  \n",
            "110_tranformerblock_6.leff.layer2.Conv2d_0      1.179648M  \n",
            "111_tranformerblock_6.leff.layer2.GELU_1                -  \n",
            "112_tranformerblock_6.leff.layer3.Linear_0        32.768k  \n",
            "113_upsample_2.deconv.ConvTranspose2d_0        16.777216M  \n",
            "114_tranformerblock_7.LayerNorm_norm1               128.0  \n",
            "115_tranformerblock_7.Dropout_dropout                   -  \n",
            "116_tranformerblock_7.w_msa.Linear_qkv            49.152k  \n",
            "117_tranformerblock_7.w_msa.Dropout_attn_drop           -  \n",
            "118_tranformerblock_7.w_msa.Linear_qkv            49.152k  \n",
            "119_tranformerblock_7.w_msa.Dropout_attn_drop           -  \n",
            "120_tranformerblock_7.w_msa.Linear_proj           16.384k  \n",
            "121_tranformerblock_7.w_msa.Dropout_proj_drop           -  \n",
            "122_tranformerblock_7.LayerNorm_norm2               128.0  \n",
            "123_tranformerblock_7.Dropout_dropout                   -  \n",
            "124_tranformerblock_7.leff.layer1.Linear_0        16.384k  \n",
            "125_tranformerblock_7.leff.layer1.GELU_1                -  \n",
            "126_tranformerblock_7.leff.layer2.Conv2d_0      1.179648M  \n",
            "127_tranformerblock_7.leff.layer2.GELU_1                -  \n",
            "128_tranformerblock_7.leff.layer3.Linear_0        16.384k  \n",
            "129_upsample_3.deconv.ConvTranspose2d_0        16.777216M  \n",
            "130_tranformerblock_8.LayerNorm_norm1                64.0  \n",
            "131_tranformerblock_8.Dropout_dropout                   -  \n",
            "132_tranformerblock_8.w_msa.Linear_qkv            12.288k  \n",
            "133_tranformerblock_8.w_msa.Dropout_attn_drop           -  \n",
            "134_tranformerblock_8.w_msa.Linear_qkv            12.288k  \n",
            "135_tranformerblock_8.w_msa.Dropout_attn_drop           -  \n",
            "136_tranformerblock_8.w_msa.Linear_proj            4.096k  \n",
            "137_tranformerblock_8.w_msa.Dropout_proj_drop           -  \n",
            "138_tranformerblock_8.LayerNorm_norm2                64.0  \n",
            "139_tranformerblock_8.Dropout_dropout                   -  \n",
            "140_tranformerblock_8.leff.layer1.Linear_0         8.192k  \n",
            "141_tranformerblock_8.leff.layer1.GELU_1                -  \n",
            "142_tranformerblock_8.leff.layer2.Conv2d_0      1.179648M  \n",
            "143_tranformerblock_8.leff.layer2.GELU_1                -  \n",
            "144_tranformerblock_8.leff.layer3.Linear_0         8.192k  \n",
            "145_output_proj.proj.Conv2d_0                   1.769472M  \n",
            "146_output_proj.proj.LeakyReLU_1                        -  \n",
            "-------------------------------------------------------------------------------------------------------\n",
            "                           Totals\n",
            "Total params            8.287907M\n",
            "Trainable params        8.287907M\n",
            "Non-trainable params          0.0\n",
            "Mult-Adds             110.930752M\n",
            "=======================================================================================================\n",
            "The Uformer model has: 8287907 trainable parameters\n",
            "--- Start training: Uformer ---\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 - Training: 100%|██████████| 32/32 [01:57<00:00,  3.68s/step, Loss=9.51]\n",
            "Epoch 1/100 - Validation: 100%|██████████| 64/64 [00:33<00:00,  1.94step/s, Loss=10.4]\n",
            "Epoch 2/100 - Training: 100%|██████████| 32/32 [01:56<00:00,  3.63s/step, Loss=9.42]\n",
            "Epoch 2/100 - Validation: 100%|██████████| 64/64 [00:33<00:00,  1.91step/s, Loss=10.4]\n",
            "Epoch 3/100 - Training: 100%|██████████| 32/32 [01:57<00:00,  3.68s/step, Loss=9.51]\n",
            "Epoch 3/100 - Validation: 100%|██████████| 64/64 [00:34<00:00,  1.86step/s, Loss=10.3]\n",
            "Epoch 4/100 - Training: 100%|██████████| 32/32 [01:58<00:00,  3.69s/step, Loss=9.42]\n",
            "Epoch 4/100 - Validation: 100%|██████████| 64/64 [00:33<00:00,  1.91step/s, Loss=10.2]\n",
            "Epoch 5/100 - Training: 100%|██████████| 32/32 [01:57<00:00,  3.66s/step, Loss=9.32]\n",
            "Epoch 5/100 - Validation: 100%|██████████| 64/64 [00:32<00:00,  1.95step/s, Loss=10.1]\n",
            "Epoch 6/100 - Training: 100%|██████████| 32/32 [01:57<00:00,  3.69s/step, Loss=9.41]\n",
            "Epoch 6/100 - Validation: 100%|██████████| 64/64 [00:32<00:00,  1.94step/s, Loss=10.1]\n",
            "Epoch 7/100 - Training: 100%|██████████| 32/32 [01:58<00:00,  3.69s/step, Loss=9.54]\n",
            "Epoch 7/100 - Validation: 100%|██████████| 64/64 [00:32<00:00,  1.98step/s, Loss=9.92]\n",
            "Epoch 8/100 - Training: 100%|██████████| 32/32 [01:55<00:00,  3.62s/step, Loss=9.32]\n",
            "Epoch 8/100 - Validation: 100%|██████████| 64/64 [00:34<00:00,  1.87step/s, Loss=10.5]\n",
            "Epoch 9/100 - Training: 100%|██████████| 32/32 [01:58<00:00,  3.69s/step, Loss=9.38]\n",
            "Epoch 9/100 - Validation: 100%|██████████| 64/64 [00:34<00:00,  1.86step/s, Loss=10.2]\n",
            "Epoch 10/100 - Training: 100%|██████████| 32/32 [01:55<00:00,  3.62s/step, Loss=9.36]\n",
            "Epoch 10/100 - Validation: 100%|██████████| 64/64 [00:32<00:00,  1.96step/s, Loss=10.1]\n",
            "Epoch 11/100 - Training: 100%|██████████| 32/32 [01:57<00:00,  3.68s/step, Loss=9.41]\n",
            "Epoch 11/100 - Validation: 100%|██████████| 64/64 [00:33<00:00,  1.92step/s, Loss=10.1]\n",
            "Epoch 12/100 - Training: 100%|██████████| 32/32 [01:57<00:00,  3.67s/step, Loss=9.27]\n",
            "Epoch 12/100 - Validation: 100%|██████████| 64/64 [00:33<00:00,  1.93step/s, Loss=10.3]\n",
            "Epoch 13/100 - Training: 100%|██████████| 32/32 [01:56<00:00,  3.63s/step, Loss=9.46]\n",
            "Epoch 13/100 - Validation:  20%|██        | 13/64 [00:08<00:31,  1.60step/s, Loss=11.2]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-342-aecdec0238bd>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# optimizer = torch.optim.SGD(model.parameters(), lr=global_var['lr'], weight_decay = 0.005, momentum = 0.9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_var\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-341-e15b14a5e035>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(device, model, optimizer, criterion, train_dataloader, test_dataloader)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m           \u001b[0;31m# Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m           \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m           \u001b[0mtest_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-338-f2b314d06a27>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "device = hardware_check()\n",
        "\n",
        "model = Uformer()\n",
        "model.to(device)\n",
        "\n",
        "criterion = Cha_loss()\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=global_var['lr'], weight_decay = 0.005, momentum = 0.9)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=global_var['lr'], betas=(0.9, 0.999), eps=1e-08, weight_decay=0.02)\n",
        "stats = train(device,model,optimizer,criterion,train_loader,test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(save_model_root+\"stats_patch.pkl\", 'wb') as f:\n",
        "  pickle.dump(stats,f)\n",
        "\n",
        "with open(save_model_root+\"stats_patch.pkl\", 'rb') as f:\n",
        "  data = pickle.load(f)"
      ],
      "metadata": {
        "id": "kuOgkSq-JVHu"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = data[0]['train_loss']\n",
        "train_losses = data[4]\n",
        "test_losses = data[5]\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(25,5))\n",
        "\n",
        "ax.plot(a)\n",
        "print(len(train_losses))\n",
        "# print(len(test_losses))\n",
        "# train_stats = data[0]\n",
        "# train_stats.keys()\n",
        "\n",
        "# train_stats['train_loss']\n",
        "\n",
        "# fig, ax = plt.subplots(4, 1, figsize=(5,5))\n",
        "# epochs = torch.linspace(0,global_var['epochs'],steps=960)\n",
        "\n",
        "# ax[0].set_title(\"Train loss\")\n",
        "# ax[0].plot(epochs,train_stats['train_loss'], color='orange')\n",
        "# ax[0].set_ylabel('Loss')\n",
        "# ax[0].set_xlabel('Epochs')\n",
        "\n",
        "# ax[1].set_title(\"Test loss\")\n",
        "# ax[1].plot(epochs,train_stats['val_loss'], color='red')\n",
        "# ax[1].set_ylabel('Loss')\n",
        "# ax[1].set_xlabel('Epochs')\n",
        "\n",
        "# ax[2].set_title(\"Train accuracy\")\n",
        "# ax[2].plot(epochs,train_stats['train_acc'], color='blue')\n",
        "# ax[2].set_ylabel('Loss')\n",
        "# ax[2].set_xlabel('Epochs')\n",
        "\n",
        "# ax[3].set_title(\"Test accuracy\")\n",
        "# ax[2].plot(epochs,train_stats['val_acc'], color='green')\n",
        "# ax[3].set_ylabel('Loss')\n",
        "# ax[3].set_xlabel('Epochs')\n",
        "\n",
        "# fig.tight_layout()"
      ],
      "metadata": {
        "id": "bq3N-KbJbVdX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "31bf75f5-6964-4f75-a75e-48c741b9fb27"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV0TTJ-b34SV"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 349,
      "metadata": {
        "id": "DkN_h9E935rb"
      },
      "outputs": [],
      "source": [
        "def test(device,test_dataloader):\n",
        "  model = Uformer()\n",
        "  model = load_pretrained_model(model,device)\n",
        "  model.to(device)\n",
        "\n",
        "  # if global_var['do_print_model']:\n",
        "  #   print_model(model, device, input_shape=global_var['RGB_img_res'])\n",
        "    # print('The {} model has: {} trainable parameters'.format(model_name, count_parameters(model)))\n",
        "\n",
        "  # Evaluate\n",
        "  print(\" --- Begin evaluation --- \")\n",
        "  mean_psnr, mean_ssim = compute_evaluation(test_dataloader,model,device)\n",
        "  print(\" --- End evaluation --- \")\n",
        "  print(\"Mean PSNR: \",mean_psnr)\n",
        "  print(\"Mean SSIM: \",mean_ssim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 350,
      "metadata": {
        "id": "Q9TdNFPC6x14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94198aaa-120f-4fbb-bcec-0ee7702ad49c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint...\n",
            "\n",
            "Checkpoint loaded!\n",
            "\n",
            " --- Begin evaluation --- \n",
            " --- End evaluation --- \n",
            "Mean PSNR:  27.026185989379883\n",
            "Mean SSIM:  0.483076810836792\n"
          ]
        }
      ],
      "source": [
        "test(device,test_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "y_wpJixyu0uG",
        "5KVlRJ0lu7eU",
        "smh0pVrvtHTZ",
        "JXRFscaCxaY7",
        "KhjFnJ-yyaCJ",
        "wr4UgpsTQNXr",
        "maczFOi8eB52",
        "lV0TTJ-b34SV"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}